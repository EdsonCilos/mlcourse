{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Projeto_offline_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6T9pPKu28Mwe",
        "UBjzryXYKMb5",
        "HMaugIFD5xmR",
        "hEd0_zms8M3Q",
        "f3xjl8BZonWR",
        "v-evQ2rCHjqa",
        "ksZpTGM9pQ6m"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t2Qabg58MwS"
      },
      "source": [
        "**Projeto offline de aprendizado de máquina de ponta a ponta**\n",
        "\n",
        "---\n",
        "\n",
        "Neste Notebook você irá criar modelos preditivos para o setor imobiliário.  Usaremos um conjunto de dados do setor imobiliário da Califórnia, baseado no censo de 1990 da cidade. \n",
        "\n",
        "As informações mais detalhadas sobre o conjunto de dados podem ser obtidas aqui [nesse artigo](https://www.sciencedirect.com/science/article/abs/pii/S016771529600140X).\n",
        "\n",
        "Este notebook foi construído baseando-se no [livro do Aurélien Géron](https://www.amazon.com.br/M%C3%A3os-obra-aprendizado-Scikit-Learn-inteligentes/dp/8550815489/ref=asc_df_8550815489/?tag=googleshopp00-20&linkCode=df0&hvadid=379715964603&hvpos=&hvnetw=g&hvrand=6748800514414021109&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=1032060&hvtargid=pla-1390910077420&psc=1) e também através do notebook do Aurélien Géron, [disponível aqui](https://github.com/ageron/handson-ml).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1cVi_NGUOO"
      },
      "source": [
        "Você verá um panorama geral de alguns dos principais passos de um projeto de machine learning:\n",
        "\n",
        "1. Enquadrar o problema;\n",
        "\n",
        "2. Obter os dados;\n",
        "\n",
        "3. Descobrir e visualizar os dados para obter informações;\n",
        "\n",
        "4. Preparar os dados para os algoritmos;\n",
        "\n",
        "5. Selecionar e treinar modelos;\n",
        "\n",
        "6. Ajustar o modelo.\n",
        "\n",
        "Para finalizar o ciclo completo de um projeto, seriam ainda necessários:\n",
        "\n",
        "7. Apresentar sua solução;\n",
        "\n",
        "8. Lançar, monitorar e manter seu sistema.\n",
        "\n",
        "Para apresentar a solução seria importante apresentar de maneira organizada e sistematizada as análises que faremos aqui neste notebook. Podería-se ainda criar uma narrativa para que esses resultados fossem apresentados à gestores ou outros profissionais interessados no assunto mas que não são especialistas no assunto.\n",
        "\n",
        "A parte de lançamento, monitoramente e manuntenção do sistema envolve outras áreas da computação e ao longo do nosso curso estaremos abordando até a parte do deploy na nuvem, isto é, de implantar o modelo para que ele seja consumido por um usuário final. \n",
        "\n",
        "Como não faremos o deploy do modelo, estaremos nomeando ele de **offline** apenas para indicar que ele não estará disponível online. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T9pPKu28Mwe"
      },
      "source": [
        "# Configuração inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsm0INajpWcX"
      },
      "source": [
        "Vamos começar importando algumas bibliotecas básicas:\n",
        "\n",
        "*Numpy* - Pacote para computação científica em Python. [Saiba mais.](https://numpy.org/)\n",
        "\n",
        "*os* - Diversas interfaces para sistema operacional. [Saiba mais.](https://docs.python.org/3/library/os.html)\n",
        "\n",
        "O NumPy é extramente útil, fornecendo das mais básicas às mais avançadas técnicas de computação científica.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDJOKH5NA1QG"
      },
      "source": [
        "# Importações comuns\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvhLqbuKoskQ"
      },
      "source": [
        "Vamos agora fixar o sorteio aleatório de números no nosso projeto. Observa que isso é importante para que possamos reproduzir o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CD-_tpA7o_"
      },
      "source": [
        "#Para garantir estabilidade e ser mais fácil reproduzir experimento\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0g6E-R1rtt9"
      },
      "source": [
        "Vamos agora importar módulo básicos do [matplotlib](https://matplotlib.org/) para plotar figuras. [Confira aqui](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.rc.html) a documentação do matplotlib.rc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XilT7mJA-fx"
      },
      "source": [
        "# Para plotar figuras\n",
        "#Gráficos matplotlib incluídos no notebook, ao lado do código\n",
        "%matplotlib inline \n",
        "import matplotlib as mpl \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mpl.rc('axes', labelsize=14) \n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDgr37xgBVsA"
      },
      "source": [
        "É comum que alarmes sejam disparados quando há algum erro interno ao rodar os códigos. Em geral é importante manter eles ligados pois podem nos ajudar a identificar possíveis erros no código. \n",
        "\n",
        "Por hora vamos desligar alguns warnings desnecessários relacionados ao 'internal gelsd'. Você pode conferir essa issue [aqui no GitHub](https://github.com/scipy/scipy/issues/5998). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwbr171pBB2O"
      },
      "source": [
        "# Ignorar warnings desnecessários (ver SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjzryXYKMb5"
      },
      "source": [
        "# Enquadar o problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G56JZx56qrZ"
      },
      "source": [
        "- Qual o objetivo do problema?\n",
        "\n",
        "- Como a empresa/cliente pretende usar o produto?\n",
        "\n",
        "Tais perguntas são importantes pois definirá como você vai abordar o problema, que tipo de algoritmo irá usar e qual o critério utilizado para comparar os modelos (isto é, qual métrica).\n",
        "\n",
        "Você precisará avaliar se a solução requer uma solução muito complexa, que demandará mais trabalho, tempo e dinheiro, ou se uma solução mais simples será suficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMaugIFD5xmR"
      },
      "source": [
        " # Observações importante\n",
        "\n",
        "- Antes de começar a trabalhar no projeto, verifique todas as hipóteses do sistema, infraestrutura disponível, linguagens de programação que serão utilizada, plataformas, etc. E mais importante: um projeto de machine learning é executado por **pessoas**, conhecer e dialogar com a equipe é indispensável;\n",
        "\n",
        "- Certifique-se que você dispõe dos dados corretos para construir a solução que o problema exige. Fique atento as informações e à **qualidade dos dados**, isso limitará bastante a parte de modelagem. Alguns dados podem ser inviáveis de serem coletados, seja pelo seu custo ou por tempo limitado do projeto;\n",
        "\n",
        "- Não aborde, em um primeiro momento, um problema usando a solução mais complexa possível. Otimização prematura é arriscado e pode comprometer o projeto;\n",
        "\n",
        "- Leve em consideração que os **modelos mais complexos são mais difíceis de manter**, requer estruturas mais sofisticadas (e mais caras) e geralmente requer um corpo técnico mais qualificado - fique atento também às regulamentações dos dados;\n",
        "\n",
        "- Comece com **protótipos rápidos** e vá conversando com o cliente obtendo retorno sobre as necessidades do produto. Já pensou passar meses desenvolvendo um produto e no final não era o que o cliente queria? A agilidade em fazer protótipos em Python torna essa linguagem muito interessante!\n",
        "\n",
        "- As nossas visões, opiniões vão mudando com o tempo, então é natural que o cliente (e você!) vá amadurecendo ao longo do processo. **Comunicação** é a palavra chave.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU8EFsXB8Mwz"
      },
      "source": [
        "# Obtendo os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7EBBu6Eyyr6"
      },
      "source": [
        "Nesta etapa você deverá obter os dados necessários ao problema. A função definida à serguir faz um htpp request no link, faz download do arquivo zip e após isso extrai os dados, salvando no diretório \"datasets/housing\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7N5Z56F8Mw3"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True) #Cria diretorio\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\") #caminho do arquivo\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path) #request data\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close() #Importante!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InzGdJMr8Mw_"
      },
      "source": [
        "fetch_housing_data() #Cria diretório datasets/housing no espaço de trabalho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O7_U2bT1dVB"
      },
      "source": [
        "Vamos importar a biblioteca do pandas que é extremamente útil para lidar dataframs (tabela de dados). Vamos carregar os dados no diretório criado, criando um ***pandas frame*** que conterá as informações do arquivo housing.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdF8chZz8MxH"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path) #Função do pandas para carregar arquivo CSV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAw-T6N88MxQ"
      },
      "source": [
        "housing = load_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pyrlvhc7UKA"
      },
      "source": [
        "# Conheçendo os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrkY3oWp7b9k"
      },
      "source": [
        "Vamos começar visualizando as 5 primeiras linhas do dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCjYEUDH7ZAU"
      },
      "source": [
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IV8ScPJ6P_L"
      },
      "source": [
        "Observa que todas as 5 primeiras amostras tem ocean_proximity = 'NEAR BAY', o que pode indicar que os dados estejam de certa forma ordenados.  \n",
        "\n",
        "Vamos fazer então o seguinte: vamos coletar uma amostra contendo 10 instâncias para visualizar os nossos dados. Observa que esse processo envolve uma aleatoriedade, daí a importância de fixar random_state em um certo valor caso você tenha interesse em reproduzir o experimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erjyqxzn57Oc"
      },
      "source": [
        "housing.sample(n = 10, random_state = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upDO8yv64ai1"
      },
      "source": [
        "Olha que interessante! Se você usar a seed fixada no início (42), você observará que tem dados faltantes no número total de quartos.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is1_dSbF7MeL"
      },
      "source": [
        "Vamos agora nos informar a respeito das variáveis do problemas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae6oJj4R8MxZ"
      },
      "source": [
        "housing.info() #Rápida descrição dos dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzN0Y0kpK8CQ"
      },
      "source": [
        "É importante também saber **como** esse dataset foi **construído**. \n",
        "\n",
        "Primeiro, usou-se dados brutos do censo de 1990 da Califórnia. \n",
        "\n",
        "* Calculou-se os centróides de cada quarteirão da Califórnia, medido em latitude e longitude.\n",
        "\n",
        "* Foram excluídos todos os quarteirões que tinha entradas faltantes.\n",
        "\n",
        "As características (**features**) são as seguintes:\n",
        "\n",
        "\n",
        "1. longitude: longitude do centro do quarteirão;\n",
        "\n",
        "2. latitude: latitude do centro do quarteirão;\n",
        "\n",
        "3. housing_median_age: idade mediana de uma casa dentro de um quarteirão; \n",
        "4. total_rooms: número total de quartos em uma quadra;\n",
        "\n",
        "5. total_bedrooms: número total de quartos em uma quadra;\n",
        "\n",
        "6. population: número total de pessoas residentes em um quarteirão;\n",
        "\n",
        "7. households: número total de famílias em um quarteirão;\n",
        "\n",
        "8. median_income: renda mediana para famílias em um quarteirão de casas (medida em dezenas de milhares de dólares);\n",
        "\n",
        "9. median_house_value : valor médio da casa para famílias em um bloco (medido em dólares americanos);\n",
        "\n",
        "10. ocean_proximity: localização da quadra em relação ao mar/oceano.\n",
        "\n",
        "As informações são do [artigo](https://www.sciencedirect.com/science/article/abs/pii/S016771529600140X)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZyjfvEmJBZk"
      },
      "source": [
        "Todos as características são numéricas, exceto a proximidade do oceano (último atributo). Nesse caso, sabemos que o último campo é na verdade do tipo texto, embora o Python tenha carregado como um objeto genérico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPr0m4-t8Mxg"
      },
      "source": [
        "housing[\"ocean_proximity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8TL_7-vJhCN"
      },
      "source": [
        "Como podemos observar, a característica \"proximidade do oceano\" é um atributo \n",
        "categórico.\n",
        "\n",
        "Vamos agora extrair algumas medidas resumo do nosso conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUqXwjN_8Mxo"
      },
      "source": [
        "housing.describe() #Medidas resumo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2QW6q9C9GAG"
      },
      "source": [
        "Alguns histogramas também são úteis para compreender o problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaNOxfbs8Mxv"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4F7JWQ1BcEY"
      },
      "source": [
        "#Separando o conjunto de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlJskFrg9RRV"
      },
      "source": [
        "Se quisermos utilizar um conjunto de teste para realizar uma estimativa \"não enviesada\" do modelo final é importante já separarmos o conjunto de treino e teste desde já.\n",
        "\n",
        "Observa que a função train_test_split implentada no scikit-learn tem como padrão shuffle = True. Isto quer dizer que ele irá embaralhar os dados e então fara a divisão do conjunto de dados em treino e teste. \n",
        "\n",
        "<font color='red'>É importante que os dados sejam embaralhados pois é comum que exista algum tipo de ordenação nos dados, de forma que se você não embaralhar os dados estará introduzindo tendencias ou vieses que não existem nos dados reais. </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFwcG5uQ8Myy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, \n",
        "                                       test_size=0.2, #20% para teste\n",
        "                                       random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4Qyw_sGrHT"
      },
      "source": [
        "Essa divisão no conjunto de dados é até então puramente aleatória. Será que esse tipo de divisão é a mais indicada?\n",
        "\n",
        "Vejamos novamente as medidas resumo da renda mediana:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQIbYlWULvGo"
      },
      "source": [
        "housing[\"median_income\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03822zBOK9ss"
      },
      "source": [
        "mean = np.mean(housing[\"median_income\"])\n",
        "std = np.std(housing[\"median_income\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGNLaRDmQX1d"
      },
      "source": [
        "Lembrando que \"median_income\" é a renda mediana para famílias em um quarteirão de casas (medida em dezenas de milhares de dólares). Nesse caso, a **maior parte dos quarteirões tem renda mediana entre 20 mil e 58 mil dólares***.\n",
        "\n",
        "\n",
        "***Observação:** mean ~= 3.87, corresponde a uma renda anual mediana de 38 mil e 700 dólares. Neste caso, calculando o intervalo [mean - std, mean + std], em um modelo gaussiano teríamos aproxidamente 68% da distribuição dos dados. Daí a afirmação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-IxG3fpMNw8"
      },
      "source": [
        "\n",
        "Vamos agora fazer uma estratificação da renda, pois é importante ter um número suficiente de instâncias para cada estrato no conjunto de dados (treino e testes), do contrário pode ser que os nossos dados fiquem enviasados, não representando adequadamente a população. Em uma amostra suficientemente grande isso não seria um problema.\n",
        "\n",
        "Dependendo do problema, a questão da discussão do tipo de amostragem deve ser discutida com um **estatístico**.\n",
        "\n",
        "Vamos supor que tenhamos feito esse processo, de discutir com um estatístico a respeito do problema e foi nos informado que é importante separar a renda dos quarteirões em estratos para abordar o problema adequadamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux8EH3u8Ip6k"
      },
      "source": [
        "Vamos dividir a renda em 5 estratos, de 15 em 15 mil doláres. Não há nenhuma mágica nessa escolha, senão a questão da facilidade. O correto seria, mais uma vez, usar informações sociais discutidas com o estatístico\n",
        "\n",
        "Faremos isso criando uma nova feature no nosso dataset. Esse processo de criar novas categorias a partir do conhecimento do problema é chamado de **feature engineering** e abordaremos melhor mais à frente no nosso projeto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKwkmUlbOjWi"
      },
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "housing[\"income_cat\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NuMgAShs8MzJ"
      },
      "source": [
        "housing[\"income_cat\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwYnXUa7TK0c"
      },
      "source": [
        "Pronto! Agora vamos fazer uma <font color='red'>amostragem estratificada</font> com base nas categorias da renda.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "przR0ZBZ8MzT"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
        "\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi9Gp_QbTwFi"
      },
      "source": [
        "Acabamos de criar novos conjuntos de treino e de teste, que chamamos de <font color='red'>strat_train_set </font> e <font color='blue'>strat_test_set</font>.\n",
        "\n",
        " Estes conjuntos devem respeitar a estratificação que introduzimos baseada em \"median_income\" representado na nova variável categórica \"income_cat\".\n",
        "\n",
        " Vejamos se funcionou:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQb_sNWO8MzW"
      },
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set) #Proporção de cada categoria em strat_test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9att4KJX-91"
      },
      "source": [
        "housing[\"income_cat\"].value_counts() / len(housing) #Proporção de cada categoria em housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHr7e4IUYc9K"
      },
      "source": [
        "Podemos agora comparar com a <font color='blue'> amostragem aleatória </font>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcQ8FM-u8Mzi"
      },
      "source": [
        "#Função para calcular as proporções das categorias da característica \"income_cat\"\n",
        "def income_cat_proportions(data): \n",
        "    return data[\"income_cat\"].value_counts() / len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVQi0BkJZi6U"
      },
      "source": [
        "Agora vamos gerar novamente conjunto de teste e treino, mas usando amostragem aleatória."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jyVWH8ZiBM"
      },
      "source": [
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD0M3hAwZx87"
      },
      "source": [
        "Vamos criar o nosso novo dataframe e visualizar os resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-RIbMERZxOt"
      },
      "source": [
        "compare_props = pd.DataFrame({\n",
        "    \"Geral\": income_cat_proportions(housing),\n",
        "    \"Estratificado\": income_cat_proportions(strat_test_set),\n",
        "    \"Aleatorio\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "\n",
        "compare_props[\"Aleatório %erro\"] = 100 * compare_props[\"Aleatorio\"] / compare_props[\"Geral\"] - 100\n",
        "compare_props[\"Estratificado %erro\"] = 100 * compare_props[\"Estratificado\"] / compare_props[\"Geral\"] - 100\n",
        "\n",
        "compare_props"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFX8Ha0pao_z"
      },
      "source": [
        "Contentes com os resultados, não podemos esquecer de <font color='red'>remover</font> o atributo \"income_cat\" dos conjuntos strat_train_set e strat_test_set. Na verdade, ele era apenas um intermediário, afinal de contas as informações dessa caracaterísticas já estão presentes em \"median_income\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbPa45jL8Mzq"
      },
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYST0JOP8Mzu"
      },
      "source": [
        "# Visualização da estrutura de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dws-HQeEc3h0"
      },
      "source": [
        "Vamos agora visualizar os nossos dados. Precisamos ter certeza que não vamos visualizar dados do conjunto de teste, para evitar enviesamento de conclusões. \n",
        "\n",
        "De um ponto de vista mais técnico, devemos evitar o **snooping bias**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGYSWxqk8Mzv"
      },
      "source": [
        "housing = strat_train_set.copy() #Importante criar uma cópia! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1YxuAEV8Mzz"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjTUHRQYdcME"
      },
      "source": [
        "Vamos melhorar a visualição usando o parâmetro <font color='red'>alpha</font>, observe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6pNMSKy8Mz4"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnWgQnQ2dxJ4"
      },
      "source": [
        "Interessante! Agora fica mais evidente a concentração dos agrupamentos!\n",
        "\n",
        "De qualquer forma devemos voltar a nossa atenção ao objetivo: <font color = 'red'> preços do setor imobioliário. </font> \n",
        "\n",
        "No código a seguir o parâmetro \"s\" significa \"size\", tamanho em inglês. Escolhendo \"s\" como sendo a característica população, quanto maior o disco representa uma população maior.\n",
        "\n",
        "O parâmetro \"c\" significa \"color\", ou cor. Esse é na verdade o que queremos saber!\n",
        "\n",
        "O paramêtro colorbar = True indica que queremos visualizar a barra lateral informando as intensidades da cor, ou seja, do parêmetro \"c\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo34qLzu8Mz8"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "    sharex=False) #sharex=false é só pra corrigir um bug de display https://github.com/pandas-dev/pandas/issues/10611\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjuu3hmPmO3I"
      },
      "source": [
        "A visulização dos dados indicam que regiões litorâneas tendem a possuir um valor mais alto. Talevz a densidade populacional também possa ser algo relevante.\n",
        "\n",
        "Vamos então investigar essas hipóteses através da correleção estatística:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWwTwI_D8M0E"
      },
      "source": [
        "corr_matrix = housing.corr() #Matriz de correlações"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R50hJi6Sm0Ix"
      },
      "source": [
        "corr_matrix #vamos ver a estrutura"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN1XZaZk8M0H"
      },
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False) #Ordenar valores em sentido decrescente"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FDo4wlMqRlr"
      },
      "source": [
        "É conveniente usar o scatter_matrix do pandas. Essa função plota cada característica em relação a outra. No nosso exemplo, teríamos 121 possibilidades.\n",
        "\n",
        "Mas claro que não faremos isso e vamos então selecionar algumas que parecem ser mais significativas:\n",
        "\n",
        "**Dica**: Vamos aproveitar e revisar alguns [conceitos básicos de estatística](http://geam.paginas.ufsc.br/files/2020/02/Estatistica_Basica.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LpwQAvB8M0L"
      },
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Cug8hvrd6-"
      },
      "source": [
        "**OBS:** Na diagonal principal da plotagem anterior não temos atributo v.s. atributo, mas sim o histograma da característica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG0nvHx8r7Rs"
      },
      "source": [
        "Vimos antes que a característica que tinha maior correlação com o valor mediano de casas em um bairro era o salário mediano. Então vamos plotar para estudar a relação entre ambos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7tUBQjz8M0R"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV671R0AscxC"
      },
      "source": [
        "Informações desta plotagem: \n",
        "\n",
        "1.   Correlação é forte;\n",
        "\n",
        "2.   Há um valor limiar de 500.000 para os valores (medianos) das casas. Por quê?\n",
        "\n",
        "3. Há também outras linhas horizontais. Por que elas são importantes?\n",
        "\n",
        "Uma abordagem possível seria excluir os dados correspondentes a esses casos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwKPm7WPtR5y"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRpUMfun03Xe"
      },
      "source": [
        "Além das colunas que o conjunto de dados nos oferece, podemos tentar construir novas características <font color = \"red\">**construídas de maneiras não linear**</font> com as características existentes.\n",
        "\n",
        "De maneira geral, essa etapa requer conhecimento específico da área na qual se esta trabalhando. Daí a importância da presença de um especialista no assunto para auxiliar no projeto. \n",
        "\n",
        "A seguir, vamos construir algumas novas features que são mais ou menos lógicas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owOuJWl-8M0Y"
      },
      "source": [
        "#Nova feature: Número de cômodos por familia (média)\n",
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "\n",
        "#Nova feature: quartos/cômodos\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "\n",
        "#Nova feature: população/agregado familiar\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPlzoY-D2Mo-"
      },
      "source": [
        "Vejamos agora a matriz de correlação de housing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIXxphSB8M0e"
      },
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1bPs-YC3Q5-"
      },
      "source": [
        "Aparentemente, casas com uma baixa proporção de quartos por cômodos tendem a ser mais caras. O número de cômodos por família é muito mais informativo que o número total de quartos em um quarteirão.\n",
        "\n",
        "Vejamos o gráfico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO40azQw8M0i"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha=0.2)\n",
        "plt.axis([0, 5, 0, 520000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVO_3R264SaH"
      },
      "source": [
        "Vamos ver novamente as medidas resumos considerando as novas features!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Je-Uao8M0n"
      },
      "source": [
        "housing.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K22d5b-8M0q"
      },
      "source": [
        "# Preparar os dados para os algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXXVeIOY7dcH"
      },
      "source": [
        "Precisamos incialmente retirar os rótulos do conjunto <fon color='blue'> strat_train_set </font> (mais a frente ficará claro).\n",
        "\n",
        "Para isso, vamos usar o método drop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4f2vNh88M0r"
      },
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1) # O método drop cria cópia sem a coluna em questao\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy() #salvando uma cópia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nh2ij_tkjOJ"
      },
      "source": [
        "**OBS:** Ao longo desta seção estaremos chamando as features de treinamento como \"housing\". Atenção neste ponto para não confundir com o dataset inteiro. Isto é,\n",
        " tudo o que nos faremos aqui será feito somento no conjunto de treinamento!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr8Yx1Gr8-D_"
      },
      "source": [
        "A partir de agora vamos partir para etapa de <font color='blue'>**limpeza de dados!**</font>\n",
        "\n",
        "Vamos começar verificando se temos dados falantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OreIJJVV8M0v"
      },
      "source": [
        "#housing.isnull().any(axis=1) verifica quais linhas possuem alguma célula null\n",
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head() \n",
        "sample_incomplete_rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_6G0HD1tFIZ"
      },
      "source": [
        "sample_incomplete_rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g93mvTOr94j-"
      },
      "source": [
        "Possuímos basicamente três abordagens possíveis para lidar com os dados faltantes:\n",
        "\n",
        "1. Excluir os quarteirões com dados faltantes;\n",
        "\n",
        "2. Excluir toda coluna de total_bedrooms, já que é o único atributo que apresenta dados faltantes;\n",
        "\n",
        "3. Definir algum valor para substituir total_bedrooms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5Vp76w8M1A"
      },
      "source": [
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # opção 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcb4CVvy8M1D"
      },
      "source": [
        "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # opção 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwK8qP9v-3ua"
      },
      "source": [
        "Opção 3: preenchendo com algum valor - nesse caso, usaremos a mediana.\n",
        "\n",
        "Usaremos a mediana pois queremos alguma medida simples para corrigir os dados faltantes. Ao mesmo tempo, quando comparada com a média, a mediana é mais robusta a outliers o que a torna bastante interessante.\n",
        "\n",
        "É claro que existem técnicas mais sofisticadas, por exemplo, há [livros](https://www.amazon.com.br/Statistical-Analysis-Missing-Probability-Statistics-ebook/dp/B07Q25CNSD/ref=sr_1_1?__mk_pt_BR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Statistical+Analysis+with+Missing+Data&qid=1610115793&s=digital-text&sr=1-1) inteiros sobre o assunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPjSOVok8M1H"
      },
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # opção 3\n",
        "sample_incomplete_rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7E8-2jaBMyu"
      },
      "source": [
        "Se escolhermos a opção 3, devemos calular a mediana (ou qualquer outra medida que seja justificável) no <font color=\"red\">**conjunto de treinamento**</font> e usá-lo para preencher os valores faltantes neste, mas precisamos <font color=\"blue\">**salvar**</font> esse valor calculado.\n",
        "\n",
        "Você precisar desse valor para mais tarde aplicar no conjunto de teste, que deverá ter seus dados faltantes corrigidos seguindo o mesmo parâmetro do conjunto de treino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpne_3kJBInq"
      },
      "source": [
        "**AVISO**: No Scikit-Learn 0.20, a classe `sklearn.preprocessing.Imputer` \n",
        "foi substituida pela classe `sklearn.impute.SimpleImputer`. Então, é conviniente verificar qual versão o computador em questão está usando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dy5nsFz8M1M"
      },
      "source": [
        "try:\n",
        "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
        "    print(\"Scikit-Learn 0.20+\")\n",
        "except ImportError:\n",
        "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
        "    print(\"Scikit-Learn antes do 0.20\")\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0iuZ4GFC2Wk"
      },
      "source": [
        "Vamos novamente revisar o nosso dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC1UXCMtC7Dr"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R3RrWmp8M1O"
      },
      "source": [
        "Ainda temos a última coluna que não é numérica! \n",
        "\n",
        "A princípios, grande parte dos algoritmos de machine learning no computador preferem os dados representados numericamente!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtSZSuXK8M1P"
      },
      "source": [
        "housing_num = housing.drop('ocean_proximity', axis=1)\n",
        "# Derrubando a coluna \"ocean_proximity\"\n",
        "# alternativa: housing_num = housing.select_dtypes(include=[np.number])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oJNfnSNDrea"
      },
      "source": [
        "Agora vamos ajudar o nosso objeto imputer com o nossos dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEXT2hQr8M1S"
      },
      "source": [
        "imputer.fit(housing_num) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ5SdBuUD27i"
      },
      "source": [
        "Aqui, o imputer simplesmente calculou a mediana no conjunto de dados.\n",
        "\n",
        "Vejamos algumas informações sobre o nosso objeto imputer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP3wAcyX8M1W"
      },
      "source": [
        "imputer.statistics_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o1__l6p8M1a"
      },
      "source": [
        "Vamos verificar que isto é, na verdade, a mesma coisa que calcular manualmente a mediana de cada atributo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Qi1YJc8M1c"
      },
      "source": [
        "housing_num.median().values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8fmJCklEhzx"
      },
      "source": [
        "**Mas não seria apenas o atributo total_bedrooms que estava com valores faltantes?** \n",
        "\n",
        "Vamos precisar de todas as informações do imputer? Isto é, vamos precisar da mediana de todas as variáveis?\n",
        "\n",
        "<font color='red'> **Não podemos, a princípio, afirmar que o mesmo padrão vai ser repetir na generalização do modelo!** </font>\n",
        "\n",
        "Certo, mas e se dermos uma espiadinha no conjunto de testes?\n",
        "\n",
        "Não devemos fazer isso por vários motivos. \n",
        "\n",
        "1. Corremos o risco de colocar vieses no nosso modelo (assumir que apenas \"total_bedrooms\" terá colunas com dados faltantes em todos os cenários possíveis é um deles);\n",
        "\n",
        "2. Devemos ter sempre em mente que o conjunto de teste é no fundo uma simulação para testarmos o poder de generalização do algoritmo - devemos fazer todas as nossas análises e otimizações somente no conjunto de treinamento e então aplicar o modelo final uma única vez no conjunto de teste!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5gUu6H8M1j"
      },
      "source": [
        "Vamos agora finalmente <font color = 'blue'> transformar </font> o nosso conjunto de dados, aplicando, efetivamente, o valor calculado da mediana nos dados faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeMG56He8M1k"
      },
      "source": [
        "X = imputer.transform(housing_num) #numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWZP3rviHVT3"
      },
      "source": [
        "Vamos visualizar o conjunto X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhW6FTsHYCA"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM-cJ1LiHaS2"
      },
      "source": [
        "Se você se sentir mais confortável, pode transformar o conjunto X em um dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9CX4hOO8M1n"
      },
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns, #importante informar nome das colunas\n",
        "                          index=housing.index) #DataFrame Pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9szVFMcHhQa"
      },
      "source": [
        "Vejamos como é este dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mYCY8ltHlcD"
      },
      "source": [
        "housing_tr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ_0PzGe8M1y"
      },
      "source": [
        "Agora devemos tratar a variável categórica`ocean_proximity'!\n",
        "\n",
        "Lembre que esta é uma variável muito importante no nosso problema: ela demonstrava uma boa correlação com o preço mediano das casas.\n",
        "\n",
        "Vamos novamente visualizar os dados para relembrar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zZc51Ro8M1z"
      },
      "source": [
        "housing_cat = housing[['ocean_proximity']]\n",
        "housing_cat.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHlDGSPp9drc"
      },
      "source": [
        "Agora vamos usar um processo chamado de codificação. Vamos transformar as nossas variáveis categóricas em números!\n",
        "\n",
        "<font color = 'red'>**Agora é um bom momento para olhar o noteobok de [apoio](https://github.com/edsonjunior14/mlcourse/blob/master/material_apoio_codificacao.ipynb) :**)</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBeHjNq58M12"
      },
      "source": [
        "**OBS**: O código a seguir é apenas devido a atualização da classe OrdinalEnconder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCgAnVEN8M13"
      },
      "source": [
        "try:\n",
        "    from sklearn.preprocessing import OrdinalEncoder\n",
        "    print(\"Scikit-Learn >= 2.0\")\n",
        "except ImportError:\n",
        "    from future_encoders import OrdinalEncoder # Scikit-Learn < 0.20\n",
        "    print(\"O teu Scikit-Learn tá antiguinho mô quirido\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jTIHNpV-YC0"
      },
      "source": [
        "Na função a seguir, precisamos instanciar um objeto ordinal_encoder. \n",
        "\n",
        "Depois, usamos fit_transform para executa duas operações:\n",
        "\n",
        "1. Método fit irá ajustar os parâmetros (mapeamento, por exemplo, quais são as variáveis categóricas); \n",
        "\n",
        "2. Método transform irá transformar os dados;\n",
        "\n",
        "3. fit_transform(dados) irá ajustar parâmetros e transformar os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6IUvOsv8M15"
      },
      "source": [
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAELI6TN_JMO"
      },
      "source": [
        "Uma alternativa mais prolixa teria sido escrever:\n",
        "\n",
        "original_encoder.fit(housing_cat)\n",
        "\n",
        "housing_cat_encoded = original_enconder.transform(housing_cat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35TkntyX_JgN"
      },
      "source": [
        "Vejamos que tipo de objeto é housing_cat_encoded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaHZCal8CNLd"
      },
      "source": [
        "type(housing_cat_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GhaDm9TCQUd"
      },
      "source": [
        "Vamos ver agora os 10 primeiros valores desse numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZwZlPvV_J-B"
      },
      "source": [
        "housing_cat_encoded[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71JIk01_CaPi"
      },
      "source": [
        "Vamos relembrar também as categorias do nosso problema:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGFUci_p8M18"
      },
      "source": [
        "ordinal_encoder.categories_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1uKeQbJ_IDx"
      },
      "source": [
        "**Veja!**\n",
        "\n",
        "O objeto ordinal_encoder foi construiído assim:\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder() \n",
        "\n",
        "e depois fizemos o seguinte:\n",
        "\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "\n",
        "<font color = \"red\">**Aqui não apenas definimos quem é \"housing_cat_encoded\" como também inserimos informações no objeto ordinal_encoder!** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMDgx9IXDQp4"
      },
      "source": [
        "Apesar dos nossos esforços, temos um grave problema na nossa codificação, veja novamente: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej67X1XiGuVB"
      },
      "source": [
        "housing_cat_encoded[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d9Wk1zfDYLy"
      },
      "source": [
        "housing_cat[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxpbZPyhDaFA"
      },
      "source": [
        "Cada variável categórica foi transformada em número!\n",
        "\n",
        "Mas será que a princípio, podemos comparar uma variável categórica com outra?\n",
        "\n",
        "Quem é maior: NEAR OCEAN ou NEAR BAY? \n",
        "\n",
        "Bem, é difícil responder. Mas é isso que a nossa codificação implicítacamente está fazendo ao colocar os valores 0, 1, 2, 3 ou 4 para cada variável categórica. \n",
        "\n",
        "<font color=\"red\"> **Para lidar com essa situação precisamos então de outra abordagem!**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRx3EyM_8M2A"
      },
      "source": [
        "try:\n",
        "    from sklearn.preprocessing import OrdinalEncoder # gera um ImportError se Scikit-Learn < 0.20\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "except ImportError:\n",
        "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n",
        "\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxZNJ3vdLhsy"
      },
      "source": [
        "Epa! Agora temos uma matriz SciPy ao invés de um Numpy array! \n",
        "\n",
        "<font color = \"red\">Por que será?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmFwJfi8M2D"
      },
      "source": [
        "Por padrão a classe `OneHotEncoder` retorna uma matriz (array) esparso, mas podemos transformá-la convertendo em uma matriz chamando o método `toarray()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9Ui84j8M2F"
      },
      "source": [
        "housing_cat_1hot.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Awc-A88M2H"
      },
      "source": [
        "Alternativamente, podemos colocar `sparse=False` ao criar o objeto `OneHotEncoder`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBpRUzXa8M2K"
      },
      "source": [
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffDhyjCS8M2Q"
      },
      "source": [
        "cat_encoder.categories_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBb4phIC8M2S"
      },
      "source": [
        "Vamos criar um transformador customizado para adicionar atributos extras \n",
        "\n",
        "**OBS**:\n",
        "- Vamos criar um código para o processo manual feito na etapa de Feature Engineering. \n",
        "\n",
        "- Vai nos ajudar a criar um pipeline mais a frente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elcx_lHE8M2T"
      },
      "source": [
        "housing.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9EO6KsJ8M2a"
      },
      "source": [
        "Alternativamente, você pode usar a função da classe `FunctionTransformer` que permite você criar rapidamente um \n",
        "transformador baseado em uma função de transformação! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rpc96Bz8M2b"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\n",
        "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
        "    list(housing.columns).index(col)\n",
        "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
        "\n",
        "def add_extra_features(X, add_bedrooms_per_room=True):\n",
        "\n",
        "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
        "\n",
        "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
        "\n",
        "    if add_bedrooms_per_room:\n",
        "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "\n",
        "        return np.c_[X, rooms_per_household, \n",
        "                     population_per_household,\n",
        "                     bedrooms_per_room]\n",
        "    else:\n",
        "        return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = FunctionTransformer(add_extra_features, \n",
        "                                 validate=False,\n",
        "                                 kw_args={\"add_bedrooms_per_room\": False})\n",
        "\n",
        "housing_extra_attribs = attr_adder.fit_transform(housing.values)\n",
        "\n",
        "#Vale colocar validate=False já que os dados não possuem valores não-float\n",
        "#validate=false é valor padrão a partir do Scikit-Learn 0.22."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Kxr65r8M2d"
      },
      "source": [
        "housing_extra_attribs = pd.DataFrame(\n",
        "    housing_extra_attribs,\n",
        "    columns= list(housing.columns) + [\"rooms_per_household\", \n",
        "                                      \"population_per_household\"],\n",
        "    index=housing.index)\n",
        "\n",
        "housing_extra_attribs.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQWec1HG8M2k"
      },
      "source": [
        "Agora vamos construir um \"[pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline)\" (tradução literal: gasoduto) para pré-processar os atributos numéricos.\n",
        "\n",
        "A ideia do pepeline é aplicar, nesta ordem, as seguintes transformações:\n",
        "\n",
        "*   Dados faltantes são imputadas\n",
        "*   Novas features são adicionadas (feature engineering)\n",
        "*   As features são normalizada para que fiquem escaladas\n",
        "\n",
        "O pipeline será aprendido no conjunto de treino e depois será aplicado, usando as regras aprendidas no treinamento, no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQXJZ_Sj8M2l"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler  #StandardScaler serve para fazer a reescalar das variáveis\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdcLN1nQ8M2p"
      },
      "source": [
        "housing_num_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJnKiKU8M2s"
      },
      "source": [
        "try:\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "except ImportError:\n",
        "    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cKXHiLYj-j9"
      },
      "source": [
        "Agora devemos acrescentar o codificador no nosso pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeuhO_C28M2v"
      },
      "source": [
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "#Este é o pipeline completo!\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs), #um pipeline dentro do outro\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ]) \n",
        "\n",
        "\"\"\" Lembrando: num_pipeline é o pipeline que transforma variavéis numéricas\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "      ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "      ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
        "      ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\"\"\"\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMjEuO68M2x"
      },
      "source": [
        "housing_prepared"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZ_g_4F8M22"
      },
      "source": [
        "housing_prepared.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVtZVgtylH3S"
      },
      "source": [
        "Agora finalmente temos os nossos dados de treinamento pré-processados, assim como já temos um modelo de limpeza e tratamento de dados implentado que poderá ser aplicado no conjunto de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEd0_zms8M3Q"
      },
      "source": [
        "# Selecionar e treinar um modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNSjYgRslYpQ"
      },
      "source": [
        "Vamos começar com um modelo simples: Regressão Linear!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlfuq_N_8M3Q"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels) \n",
        "#Ei Regressão linear, encontre os parâmetros que melhor aproxima os dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jftWY8qlw0V"
      },
      "source": [
        "Vamos agora testar o nosso pipeline de pré-processamento em algumas instâncias de treino.\n",
        "\n",
        "- Observe que após os nossos esforços em apenas uma linhas conseguimos pré-processar os dados!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOEQya2loFN_"
      },
      "source": [
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data) #Full pipeline\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ee13jK88M3W"
      },
      "source": [
        "Vamos comparar agora com os valores reais:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKuAW3cF8M3W"
      },
      "source": [
        "print(\"Labels:\", list(some_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTiJNHzc8M3Z"
      },
      "source": [
        "some_data_prepared"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFbq4GnVmDQe"
      },
      "source": [
        "Agora vamos usar métricas para ver o quão bom foi o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM8zYtAz8M3c"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = MSE(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse) #Não é necessariamente obrigatório\n",
        "lin_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVUWg9TX8M3e"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "lin_mae = MAE(housing_labels, housing_predictions)\n",
        "lin_mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWmzYCImYl3"
      },
      "source": [
        "Essse modelo ainda não parece ser adequado!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j22oB0-98M3t"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state= seed)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJlEkoBQ8M3v"
      },
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = MSE(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLYetxKwmxhs"
      },
      "source": [
        "O quê? Erro zero? Aqui aconteceu o que nós chamamos de sobreajuste! Desconfie sempre quando o erro do teu modelo for zero. Isso não acontece na prática. O que indica que precisamos encontrar técnicas mais robustas para availiar os nossos modelos. \n",
        "\n",
        "Lembrando que o conjunto de teste deve ser usado apenas ao **final** do processo.\n",
        "\n",
        "No próximo bloco abordaremos uma maneira mais adequada de usar o conjunto de treinamento para avaliar os nossos modelos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3xjl8BZonWR"
      },
      "source": [
        "#Avaliação de modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEz9LMUEmHM-"
      },
      "source": [
        "Até agora estamos treinando um modelo no conjunto de treinamento e testando nele mesmo, o que não parece ser uma estratégia muito adequada.\n",
        "\n",
        " Faremos então o seguinte: vamos separar o conjunto de treinamento em k = 10 pedaços (folds) e fazemos então um loop:\n",
        "\n",
        "*   Para cada fold:\n",
        "  1.   Treine o seu modelo no conjunto formado por: treino - fold\n",
        "  2.   Teste o seu modelo no fold\n",
        "\n",
        "* Ao final, calcule uma média dos k testes anteriores\n",
        "\n",
        "Esse processo é o que chamamos de [validação cruzada](https://scikit-learn.org/stable/modules/cross_validation.html#)!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qYnAuioEkpT"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10) \n",
        "\n",
        "#cv = 10 é número de pedaços\n",
        "\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p55OzCGEmVX"
      },
      "source": [
        "**OBS:** Os recursos da validação cruzada no Scikit-Learn esperam uma função de utilidade (mais alta é melhor) ao invés de uma função custo (mais alta é pior). Assim a função de pontução é oposto à função custo (negativa). Por isso o np.sqrt(-scores) no código acima.\n",
        "\n",
        "Vejamos os resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DeXlTRkFKtF"
      },
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbGbhI8oFTI3"
      },
      "source": [
        "Vamos ver agora para o nosso modelo de regressão linear:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPtZ0GrFZAN"
      },
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARyhWZqUFawF"
      },
      "source": [
        "Note que o modelo de árvore de decisão está se sobreajustando aos dados demasiadamente, que acaba sendo pior que a regressão linear!\n",
        "\n",
        "Vamos tentar outro modelo que veremos mais adiante no curso: \"Florestas aleatórias\" para regressão. \n",
        "\n",
        "Observe que o RandomForestRegressor é uma técnica de **regressão não linear** (assim como as árvores de decisão)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWn6jjv2F7FQ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels) #Treinar modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRpy3pF9GZul"
      },
      "source": [
        "housing_predictions = forest_reg.predict(housing_prepared) #Predizer\n",
        "forest_mse = MSE(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKsl_wLG3h1"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrzsFxlBGOEq"
      },
      "source": [
        "Os resultados são melhores! \n",
        "\n",
        "Entretanto, ainda observe que a pontuação no conjunto de treino ainda é muito menor do que no conjuntos de validação, o que significa que o modelo ainda está se sobreajustando ao conjunto de treinamento.\n",
        "\n",
        "Possíveis soluções:\n",
        "- Simplificar o modelo;\n",
        "- Regularizar o modelo;\n",
        "- Obter mais dados de treinamento (hard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-evQ2rCHjqa"
      },
      "source": [
        "# Ajustando e selecionando modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGFzz4MKHubw"
      },
      "source": [
        "Vamos usar o **[Grid Search](https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search)** (busca em grades) para buscar melhores parâmetros para a nossa floresta aleatória. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpQQUMapIMvK"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # Vamos tentar 12 = 3x4 combinação de parâmetros\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # Tentar 6 = 2×3 combinações do bootstrap no modo 'Falso'\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=seed)\n",
        "\n",
        "# Vamos treinar com 5-folds, então temos (12+6)*5=90 rodadas de treinamento!!!\n",
        "\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsUrdqotITiq"
      },
      "source": [
        "A melhor combinação de parâmetros encontrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhomSWsIWUW"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhaTLTYdIj-m"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3IsMMdzIfQw"
      },
      "source": [
        "Vamos olhar a pontuação de cada hiperparâmetro testado ao longo do gridSearch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzjEiooeIuXN"
      },
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7s5KbSIvL-"
      },
      "source": [
        "pd.DataFrame(grid_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXylQP6aJEmh"
      },
      "source": [
        "Uma abordagem alternativa ao GridSearch é usar o [RandomizedSearchCV](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization). Essa nova ferrramenta de busca é indicada para quando deseja-se buscar hiperparâmetros com um número elevado de combinaçoes.\n",
        "\n",
        "- É usada da mesma maneira que o GridSearch, mas ao invés de tentar todas as combinações ela selaciona um valor aleatório para cada hiperparâmetro em cada iteração e avalia um número de combinações aleatórias;\n",
        "\n",
        "- Se você permitir muitas iterações (por exemplo, mais de 1000), ela irá explorar 1000 combinações diferentes de hiperparâmetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cdKggUAJ2YG"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=seed)\n",
        "\n",
        "rnd_search = RandomizedSearchCV(forest_reg,\n",
        "                                param_distributions=param_distribs,\n",
        "                                n_iter=10,\n",
        "                                cv=5, \n",
        "                                scoring='neg_mean_squared_error', \n",
        "                                random_state=seed)\n",
        "\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yh3N-8fJ6h8"
      },
      "source": [
        "Vejamos os resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFnkO-pLJ8dy"
      },
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A_Az1qWKAiJ"
      },
      "source": [
        "Vejamos as características mais importantes! (feature das florestas aleatórias)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3g7GuhQJ_st"
      },
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UMlgMhyKOVO"
      },
      "source": [
        "Pouco informativa... vejamos dessa forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Du3Pa8UKQzj"
      },
      "source": [
        "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        "cat_encoder = full_pipeline.named_transformers_[\"cat\"] #Importância de ter salvo\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksZpTGM9pQ6m"
      },
      "source": [
        "#Modelo e teste final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ultXdpMqpWmi"
      },
      "source": [
        "Após todas as etapas anteriores, podemos fazer o teste final do nosso modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUADiq60KfHz"
      },
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = MSE(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBKt_lIqQDDw"
      },
      "source": [
        "final_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoVyp0yZLLS3"
      },
      "source": [
        "# Depois? \n",
        "\n",
        "\n",
        "*   Elabore uma apresentação e construa uma narrativa para apresentar os resultados;\n",
        "\n",
        "*   Lance, monitore e mantenha seu sistema:\n",
        "\n",
        "  1.  Preparar solução para produção;\n",
        "\n",
        "  2.  Código de monitoramente para verificar com certa frequência o desempenho;\n",
        "\n",
        "  3. Observe com atenção a qualidade do sinal de entrada do sistema. É importante que você mantenha em dia a qualidade dos dados oferecidos ao modelo;\n",
        "\n",
        "  4.  Lembre que as tendências vão mudando e já que grande parte dos dados são gerados a partir da atividade humana (acessos a site, uso de energia elétrica, hábitos de saúde de uma população, novas tecnologias são construídas, etc)  é natural que os dados passem a ter comportamento distintos com os passar do tempo. Portanto, fique atendo pois modelos de machine learning tendem a perder performance com o tempo;\n",
        "\n",
        "  5. Idealmente, você automatiza a etapa de coleta de dados, preparação & transformação, escolha de melhor modelo e atualização na nuvem. Se o dedo da estística estiver coçando você pode gerar relatórios automatizados de análise exploratória, de forma que uma equipe compentente possa acompanhar os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yeqS4aUtI59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}